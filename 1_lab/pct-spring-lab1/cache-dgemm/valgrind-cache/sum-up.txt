Согласно отчету Valgrind для матрицы N=1024:

    dgemm_def (Наивный вариант):

        Dr (Чтения данных): ~48,3 млрд.
        D1mr (Промахи L1): 3,229,071,360 (почти 80% всех промахов программы)
        DLmr (Промахи LL/L3): 3,225,280,512.

        Вывод: Почти каждый промах в L1 становится промахом в L3. Это означает, что данные загружаются 
        напрямую из крайне медленной оперативной памяти (RAM). Это происходит из-за обращения к матрице 
        b[k][j] по столбцам (stride-N).

    dgemm_interchange (Перестановка циклов):

        Dr (Чтения данных): Те же 48,3 млрд.
        D1mr (Промахи L1): 403,439,616.
        DLmr (Промахи LL/L3): 403,439,616.

        Вывод: Число промахов сократилось ровно в 8 раз (3.2 млрд / 403 млн ≈ 8). 
        Это идеальный результат: так как один double весит 8 байт, а кэш-линия — 64 байта, 
        один промах теперь загружает 8 чисел, которые затем используются мгновенно.

    dgemm_block (Блочный алгоритм, BS=32):

        D1mr (Промахи L1): 427,819,008.
        DLmr (Промахи LL/L3): 13,369,344.

        Вывод: Хотя промахов в L1 чуть больше, чем у interchange, промахи в L3 (DLmr) упали в 30 раз 
        относительно interchange и в 240 раз относительно def. Это и есть эффект блокировки: 
        данные почти никогда не покидают пределы кэша процессора.




        sudo sysctl -w kernel.perf_event_paranoid=-1s

        --dsos=dgemm чтобы perf не смотрел в другие программы ядра